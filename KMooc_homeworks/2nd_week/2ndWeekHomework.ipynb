{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550af786-e9f8-480f-b011-8a28356e13c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size = (640, 480)\n",
      "image mode = RGB \n",
      "image bits = 8 \n"
     ]
    }
   ],
   "source": [
    "# load images and transfer into torch\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지 입력\n",
    "img1 = Image.open(\"./1.jpg\")\n",
    "img2 = Image.open(\"./2.jpg\")\n",
    "img3 = Image.open(\"./3.jpg\")\n",
    "img1.show()\n",
    "print(\"image size = {}\".format(img1.size))\n",
    "print(\"image mode = {} \".format(img1.mode))\n",
    "print(\"image bits = {} \".format(img1.bits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbe9d75-61cc-41e2-ab29-ba9a76d2dc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor size = torch.Size([3, 480, 640])\n",
      "tensor mode = torch.return_types.mode(\n",
      "values=tensor([[0.3608, 0.3608, 0.3608,  ..., 0.6314, 0.6314, 0.6235],\n",
      "        [0.5490, 0.5490, 0.5490,  ..., 0.5725, 0.5686, 0.5765],\n",
      "        [0.8078, 0.8078, 0.8078,  ..., 0.5804, 0.5804, 0.5804]]),\n",
      "indices=tensor([[495, 282, 282,  ..., 455, 230, 261],\n",
      "        [365, 369, 391,  ..., 483, 458, 444],\n",
      "        [249, 405, 285,  ..., 516, 541, 244]]))\n",
      "tensor type = torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms.functional as tv\n",
    "\n",
    "img_tensor = tv.to_tensor(img1)\n",
    "print(\"tensor size = {}\".format(img_tensor.size()))\n",
    "print(\"tensor mode = {}\".format(img_tensor.mode()))\n",
    "print(\"tensor type = {}\".format(img_tensor.type()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f508f7b5-1446-4e6f-9a82-0bbd9883f3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print(cv2.__version__)\n",
    "img_cv2 = cv2.imread('./2.jpg')\n",
    "cv2.imshow('image', img_cv2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "               \n",
    "print(\"image size = {}\".format(img_cv2.size))\n",
    "print(\"image mode = {} \".format(img_cv2.mode))\n",
    "print(\"image bits = {} \".format(img_cv2.bits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e9848-19d4-4264-99d3-41112dcfd186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
